-----------------------
Chapter 7

MILP models
In the previous chapters, proposed problems were mostly solvable by an LP model. Nevertheless,
some advanced problem elements like order fulfillment in a whole, economy of scale and fixed costs
required integer variables, resulting in an MILP model solution. But the main problems involved,
like the production, the diet and transportation problems were continuous in nature. That is,
variables can take any value in an interval of real numbers. Integer values were only required in
specific circumstances.
In this chapter, we will see several optimization problems that involve discrete decisions, where
the solution space is not a convex continuous region, but finite – or divided into finite parts. These
problems naturally require integer, mostly binary variables to express discrete decisions, always
resulting in MILP models. Complexity is usually substantially higher than for problems involving
continuous decisions only. Some not too large MILP problem instances are difficult to impossible
to be exhaustively solved. The exact limit depends on the problem itself, the MILP model applied,
the solver software, its configuration and the machine used.

7.1

Knapsack problem

One of the simplest optimization problems that are discrete by nature is the knapsack problem
[18], its definition follows.
 
Problem 34.
Given a set of items, each having a nonnegative weight and a gain value. A weight limit is
known. Select some of the items so that their total weight does not exceed the given limit, and the
total gain is maximal.
The problem is termed as knapsack problem because it can be explained as we have a huge
knapsack which must be filled with some of the items, but the total weight we can carry is limited.
Therefore we must carefully choose which items we carry, in order to obtain the highest possible
gain.
As usual, a concrete knapsack problem instance is described for the general problem
 
Problem 35.
Solve Problem 34, the knapsack problem, with a weight capacity of 60, and the following items.

123

7.1. KNAPSACK PROBLEM
Item
Weight
Gain

A
16.1
4.4

B
19.2
4.9

MILP MODELS
C
15.0
4.3

D
14.7
4.0

E
11.3
3.7

F
20.1
5.1

G
17.5
4.6

H
14.5
4.2

I
14.8
4.3

J
18.1
4.8

Starting with the GNU MathProg implementation, first we can define the sets and parameters
describing problem data. The set Items denotes the items, and there are two parameters for each
item: Weight and Gain. A single Capacity number describes the weight limit. We set all of these
as nonnegative to avoid errors in the data section.
set Items;
param Weight {i in Items}, >=0;
param Gain {i in Items}, >=0;
param Capacity, >=0;
Implementing the data section according to Problem 35 and the sets and parameters described
here is straightforward.
set Items := A B C D E F G H I J;
param Weight :=
A 16.1
B 19.2
C 15.0
D 14.7
E 11.3
F 20.1
G 17.5
H 14.5
I 14.8
J 18.1
;
param Gain :=
A 4.4
B 4.9
C 4.3
D 4.0
E 3.7
F 5.1
G 4.6
H 4.2
I 4.3
J 4.8
;
param Capacity := 60;
Now let us think about our freedom in choosing a solution for the knapsack problem. Any
subset of all items is a possible solution, including none and all items selected. If the number of
124

7.1. KNAPSACK PROBLEM

MILP MODELS

items is n, then the number of different solutions is 2n . Note that not all of these subsets are feasible
because of the weight limit, and we can rule out many non-optimal solutions as well. Nevertheless,
the optimization problem for general weights and gains is NP-hard. Therefore, for a large n, an
exhaustive solution can be practically impossible.
In mathematical programming, we only express our freedom in decision variables. This can
be done easily in the form of a single binary variable per item. We name it select, and denotes
whether the item is chosen into the knapsack (= 1) or not (= 0).
var select {i in Items}, binary;
There is only one restriction which can prevent a solution from being feasible: the total weight
of the items. We express in a single constraint that the total weight of selected items is at most the
limit given. The total weight of the knapsack is obtained by adding each select variable multiplied
by the weight of the object. This gives the correct result, because if an item is selected in the
knapsack, its weight is added, but if not selected, nothing happens in terms of total weight of the
knapsack.
s.t. Total_Weight:
sum {i in Items} select[i] * Weight[i] <= Capacity;
The objective is the total gain which is maximized. We add each select variable multiplied by
the Gain value of the item.
maximize Total_Gain:
sum {i in Items} select[i] * Gain[i];
After the solve statement, we add some printing work to show us the solution. Our model
section is ready.
set Items;
param Weight {i in Items}, >=0;
param Gain {i in Items}, >=0;
param Capacity, >=0;
var select {i in Items}, binary;
# var select {i in Items}, >=0, <=1;
s.t. Total_Weight:
sum {i in Items} select[i] * Weight[i] <= Capacity;
maximize Total_Gain:
sum {i in Items} select[i] * Gain[i];
solve;
printf "Optimal Gain: %g\n", Total_Gain;
printf "Total Weight: %g\n",
sum {i in Items} select[i] * Weight[i];
for {i in Items}

125

7.1. KNAPSACK PROBLEM

{
}

MILP MODELS

printf "%s:%s\n", i, if (select[i]) then " SELECTED" else "";

end;
Solving Problem 35 reports an optimal gain of 17.1, which is obtained by selecting items C, E, I
and J. The total weight of these is 59.2, which fits into the limit of 60 given, although not perfectly.
Note that we used a conditional expression to print the word SELECTED after each object i
for which select[i] is 1, and nothing where it is 0. The condition of such an expression shall be a
constant expression that can be interpreted as a logical value. Remember that variables only behave
as constants after the solve statement in the model section. The output produced is the following.
Optimal Gain: 17.1
Total Weight: 59.2
A:
B:
C: SELECTED
D:
E: SELECTED
F:
G:
H:
I: SELECTED
J: SELECTED
One may think about an easy and straightforward heuristic for the knapsack problem: let us
arrange the items in the order of descending gain/weight ratios, and select items in this order
until we reach the limit. This greedy strategy seems good, because the weight limit works as a
fixed resource, therefore we need to maximize the gain obtained per unit weight. The term greedy
means that each time we make a decision, the most beneficial choice is made according to some
heuristic. Items having a larger gain/weight ratio mean a more efficient usage of the weight limit.
Actually the only problem with this strategy is the slack weight. We may (and will usually)
have some weight under the limit which is not used. However, we might probably obtain a better
solution by sacrificing some items with a higher gain/weight ratio, in order to fill the weight limit
better with other items. This is the small difference which makes the straightforward heuristic
non-optimal, and the knapsack problem difficult.
Let us consider a „relaxed” version of the knapsack problem, where items are actually fluids.
This means, we are allowed to select a fraction of an item into the knapsack, which means only the
same fraction of its weight and gain is obtained. For this relaxation, the binary variable can be
replaced by a continuous one, as follows.
var select {i in Items}, >=0, <=1;
Note that this effect can also be achieved if the original model is run with glpsol, with the
--nomip option added, as follows.
glpsol -m knapsack.mod -d example.dat --nomip
Furthermore, we change the output method a bit. Instead of printing a SELECTED word, we print
the actual value of the now continuous select variable, as follows.
126

7.1. KNAPSACK PROBLEM

MILP MODELS

for {i in Items}
{
printf "%s: %g\n", i, select[i];
}
Solving the relaxed model with the exactly same data gives the following results.
Optimal Gain: 17.7025
Total Weight: 60
A: 0.273292
B: 0
C: 1
D: 0
E: 1
F: 0
G: 0
H: 1
I: 1
J: 0
We can observe that C, E and I are common, but instead of choosing J as the fourth and last
selected item, the relaxed model chooses H, and then A in a fractional ratio. With this selection, a
prefect weight limit utilization of 60 is obtained, and a slightly better objective of 17.7025 instead
of 17.1. If we further analyze problem data, it turns out that the decreasing order of gain/weight
ratio is E, I, H, C, A, D, J, G, B, F. Therefore the relaxed model does exactly what the greedy heuristic
describes: it selects the first four items and then the fraction of the fifth (A) to fill the weight limit.
Whereas the optimal solution to the actual, integer programming problem does not choose H, instead
it chooses J, which is way down in the order, but fills better the weight limit by its larger weight
and gain.
Now that we have seen what complications may arise in case of an integer problem, let us consider
another, similar problem, the multi-way number partitioning problem [19].
