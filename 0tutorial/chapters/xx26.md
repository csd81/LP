

## Chapter 7

### MILP Models ðŸ”¢

In the previous chapters, most of the problems we presented were solvable using an **LP (Linear Programming) model**. Nevertheless, some complex elements, such as fulfilling an entire order, modeling the economy of scale, and including fixed costs, required the use of **integer variables**, which resulted in an **MILP (Mixed-Integer Linear Programming) model**. However, the main problems we looked atâ€”production, diet, and transportationâ€”were fundamentally **continuous** in nature. That is, the variables could take any value within a range of real numbers, and integer values were only necessary under specific conditions.

In this chapter, we will explore several optimization problems that inherently involve **discrete decisions**. The solution space for these problems is not a convex, continuous region but is instead **finite** (or divided into finite parts). These problems naturally require integer variables, typically **binary variables**, to express these discrete choices, inevitably leading to **MILP models**. The complexity of solving these problems is usually significantly higher than for problems involving only continuous decisions. Some MILP problem instances, even if they aren't very large, can be difficult or impossible to solve exhaustively. The exact computational limit depends on the problem itself, the specific MILP model used, the solver software and its configuration, and the machine running the calculations.

-----

### 7.1 Knapsack Problem ðŸŽ’

One of the simplest optimization problems that is discrete by nature is the **knapsack problem** [18]. Its definition is as follows:

**Problem 34.**

Given a set of **items**, each having a nonnegative **weight** and a **gain** value. A **weight limit** is known. **Select** a subset of the items so that their total weight does not exceed the given limit, and the total gain is **maximal**.

The problem is named the knapsack problem because it can be visualized as having a large knapsack that must be filled with some of the items, but the total weight you can carry is limited. Therefore, you must carefully choose which items to carry in order to obtain the highest possible gain.

As usual, we'll describe a concrete knapsack problem instance for the general problem.

**Problem 35.**

Solve **Problem 34**, the knapsack problem, with a weight **capacity of 60** and the following items:

| **Item** | **A** | **B** | **C** | **D** | **E** | **F** | **G** | **H** | **I** | **J** |
|:---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
| **Weight** | 16.1 | 19.2 | 15.0 | 14.7 | 11.3 | 20.1 | 17.5 | 14.5 | 14.8 | 18.1 |
| **Gain** | 4.4 | 4.9 | 4.3 | 4.0 | 3.7 | 5.1 | 4.6 | 4.2 | 4.3 | 4.8 |

Starting with the GNU MathProg implementation, we first define the **sets** and **parameters** that describe the problem data. The set `Items` denotes the items, and there are two parameters for each item: `Weight` and `Gain`. A single number, `Capacity`, describes the weight limit. We specify all of these as nonnegative to prevent data errors.

```glp
set Items;
param Weight {i in Items}, >=0;
param Gain {i in Items}, >=0;
param Capacity, >=0;
```

Implementing the data section according to Problem 35 and the sets and parameters described here is straightforward.

```glp
set Items := A B C D E F G H I J;
param Weight :=
A 16.1
B 19.2
C 15.0
D 14.7
E 11.3
F 20.1
G 17.5
H 14.5
I 14.8
J 18.1
;
param Gain :=
A 4.4
B 4.9
C 4.3
D 4.0
E 3.7
F 5.1
G 4.6
H 4.2
I 4.3
J 4.8
;
param Capacity := 60;
```

Now let's consider the flexibility we have in choosing a solution for the knapsack problem. Any **subset** of all items is a possible solution, including selecting none or all items. If the number of items is $n$, the total number of different solutions is $2^n$. Note that not all of these subsets are **feasible** due to the weight limit, and we can also eliminate many non-optimal solutions. Nevertheless, the general optimization problem with arbitrary weights and gains is **NP-hard**. Therefore, for a large $n$, finding an exhaustive solution may be practically impossible.

In mathematical programming, we express our decision-making freedom through **decision variables**. This can be easily done using a single **binary variable** for each item. We name it `select`; it is equal to **1** if the item is chosen into the knapsack and **0** if it is not.

```glp
var select {i in Items}, binary;
```

There is only one restriction that can prevent a solution from being feasible: the **total weight** of the items. We express in a single constraint that the total weight of the selected items is at most the given limit. The total weight in the knapsack is calculated by summing each `select` variable multiplied by the item's `Weight`. This correctly yields the result because if an item is selected, its weight is added; if it's not selected, it contributes nothing to the total weight of the knapsack.

```glp
s.t. Total_Weight:
sum {i in Items} select[i] * Weight[i] <= Capacity;
```

The objective is to **maximize** the **total gain**. We sum each `select` variable multiplied by the item's `Gain` value.

```glp
maximize Total_Gain:
sum {i in Items} select[i] * Gain[i];
```

After the `solve` statement, we add some print commands to display the solution. Our complete model section is ready:

```glp
set Items;
param Weight {i in Items}, >=0;
param Gain {i in Items}, >=0;
param Capacity, >=0;
var select {i in Items}, binary;
# var select {i in Items}, >=0, <=1;
s.t. Total_Weight:
sum {i in Items} select[i] * Weight[i] <= Capacity;
maximize Total_Gain:
sum {i in Items} select[i] * Gain[i];
solve;
printf "Optimal Gain: %g\n", Total_Gain;
printf "Total Weight: %g\n",
sum {i in Items} select[i] * Weight[i];
for {i in Items}
{
printf "%s:%s\n", i, if (select[i]) then " SELECTED" else "";
}
end;
```

Solving Problem 35 reports an **optimal gain of 17.1**, which is achieved by selecting items **C, E, I, and J**. The total weight of these items is **59.2**, which fits within the given limit of 60, though it doesn't utilize the capacity perfectly.

Note that we used a **conditional expression** to print the word `SELECTED` after each item $i$ for which `select[i]` is 1, and an empty string where it is 0. The condition for such an expression must be a constant expression that can be interpreted as a logical value. Remember that variables only behave as constants *after* the `solve` statement in the model section. The output produced is the following:

```
Optimal Gain: 17.1
Total Weight: 59.2
A:
B:
C: SELECTED
D:
E: SELECTED
F:
G:
H:
I: SELECTED
J: SELECTED
```

One might think of an easy and direct **heuristic** for the knapsack problem: arrange the items in descending order of their **gain/weight ratio** and select items in this order until the weight limit is reached. This **greedy strategy** seems promising because the weight limit acts as a fixed resource, and we want to maximize the gain obtained per unit of weight. The term "greedy" means that at each step, we make the most immediately beneficial choice according to some heuristic measure. Items with a larger gain/weight ratio represent a more efficient use of the weight limit.

The only issue with this strategy is the **slack weight**. We may (and usually will) have some unused weight under the limit. However, we might achieve a better overall solution by sacrificing an item with a high gain/weight ratio in order to better fill the remaining weight limit with other items. This small difference is what prevents the straightforward heuristic from being optimal and is what makes the knapsack problem computationally difficult.

Let's consider a **"relaxed" version** of the knapsack problem, where the items are actually fluids. This means we are allowed to select a **fraction** of an item into the knapsack, which gives us the same fraction of its weight and gain. For this relaxation, the binary variable can be replaced by a continuous one, as follows:

```glp
var select {i in Items}, >=0, <=1;
```

Note that this effect can also be achieved by running the original model with the `glpsol` solver and adding the `--nomip` option, like this:

```bash
glpsol -m knapsack.mod -d example.dat --nomip
```

Furthermore, we'll change the output method slightly. Instead of printing the word `SELECTED`, we'll print the actual value of the now continuous `select` variable:

```glp
for {i in Items}
{
printf "%s: %g\n", i, select[i];
}
```

Solving the relaxed model with the exact same data gives the following results:

```
Optimal Gain: 17.7025
Total Weight: 60
A: 0.273292
B: 0
C: 1
D: 0
E: 1
F: 0
G: 0
H: 1
I: 1
J: 0
```

We can observe that items C, E, and I are selected entirely, but instead of choosing J as the fourth and final item (as in the integer solution), the relaxed model chooses H completely and then item A in a **fractional ratio** (approximately $27.3\%$). This selection results in a perfect utilization of the weight limit (60) and a slightly better objective value of **17.7025** instead of 17.1. If we analyze the problem data further, it turns out that the items' decreasing order of **gain/weight ratio** is E, I, H, C, A, D, J, G, B, F. Therefore, the relaxed model performs exactly as the greedy heuristic dictates: it selects the first four items entirely and then the necessary fraction of the fifth (A) to fill the weight limit.

In contrast, the optimal solution to the actual **integer programming problem** does not choose H. Instead, it chooses J, which is much lower in the gain/weight ratio order, but it better fills the weight limit because of its larger overall weight and gain.

Now that we have seen the complications that can arise with an integer problem, let's consider another, similar problem: the **multi-way number partitioning problem** [19].



