---------------
Problem 7.
Given a system of linear equations, find a solution for it for which the maximum of the errors
among all equations is minimal. The error for a given equation is defined by the absolute value of
the difference between the LHS and the RHS.
(The LHS of the equation is the sum of the variables multiplied by coefficients, and the RHS is
a constant. Use the same data description method as before.)
Now, this is not a feasibility problem anymore. Being precise, now all possible values of the
variables give a feasible solution: it is just the value of the objective (maximal error) what can be
smaller or larger for some solutions. This is therefore an optimization problem.
Solving it efficiently requires a modeling trick: minimizing the maximum objective. It can
be regarded as a „design pattern” in mathematical programming.
The first part of the idea is that we introduce the objective, the maximal error itself into the
model as an individual variable as follows.
var maxError;
minimize maxOfAllErrors: maxError;
At this point, the objective is just an independent variable that can be freely set. Our problems
is to find a way that enforce this maxError variable to actually represent the maximum error of the
equations.
Suppose that L and R are the left-hand side and right-hand side values of an equation for some
values of the variables. Ideally, L = R and the error is zero. Otherwise, the error is |L − R|, which is
not a linear function of the variables. Even if it was, it would be still problematic to find a maximum
of these, because the „maximum” function is itself not linear.
Here comes our second idea. The errors themselves are not represented in the model, rather, an
upper bound for the error is used. Suppose that E is a valid upper bound for the error between L
and R, meaning |L − R| ≤ E. Now, this can be expressed as linear constraints as follows.
L−R
L−R

≤E
≥ −E

(11)

Note that E must be nonnegative, as the errors themselves are nonnegative. Alternatively, we
could say R − E ≤ L ≤ R + E. Anyways, these are two linear inequalities.
Now, what can possibly be a good candidate to be an upper bound for the error in any equations?
Well, the maximum of the errors, of course, which is denoted by maxError. Therefore we define two
constraints so that the two sides of the equations may differ at most by the amount of maxError.
s.t. Cts_Error_Up {e in Equations}:
sum {u in UnknownValues} Coef[e,u] * value[u]
<= Rhs[e] + maxError;
s.t. Cts_Error_Down {e in Equations}:
sum {u in UnknownValues} Coef[e,u] * value[u]
>= Rhs[e] - maxError;
This can be achieved by duplicating the original constraint, and involve maxError. The constraints must have unique names, here Cts_Error_Up and Cts_Error_Down were chosen.
Surprisingly, our model is ready. Now let us try to understand what happens when it is solved.
By the constraints, maxError is forced to work as a valid upper bound for the errors for all equations
at the same time. Meanwhile, maxError is an objective that is to be minimized. So these together
40

4.8. MINIMIZING ERROR

EQUATION SYSTEMS

will effectively find the least possible maxError value, for which all the equations can be satisfied
with a maximum error of maxError.
Here is the full model section, with some printf statements added to provide us a meaningful
output.
set UnknownValues;
set Equations;
param Rhs {e in Equations};
param Coef {e in Equations, u in UnknownValues}, default 0;
var value {u in UnknownValues};
var maxError;
s.t. Cts_Error_Up {e in Equations}:
sum {u in UnknownValues} Coef[e,u] * value[u]
<= Rhs[e] + maxError;
s.t. Cts_Error_Down {e in Equations}:
sum {u in UnknownValues} Coef[e,u] * value[u]
>= Rhs[e] - maxError;
minimize maxOfAllErrors: maxError;
solve;
printf "Optimal error: %g\n", maxError;
printf "Variables:\n";
for {u in UnknownValues}
{
printf "%s = %g\n", u, value[u];
}
printf "Equations:\n";
for {e in Equations}
{
printf "%5s: RHS=%10f, actual=%10f, error=%10f\n",
e, Rhs[e],
sum {u in UnknownValues} Coef[e,u] * value[u],
abs(sum {u in UnknownValues} Coef[e,u] * value[u] - Rhs[e]);
}
end;
If we solve it we get the following results.
Optimal error: 0.478261
Variables:
x = -3.42029

41

4.9. EQUATION SYSTEMS – SUMMARY

EQUATION SYSTEMS

y = -1.21884
z = 2.24058
w = 3.23768
v = -0.36087
Equations:
Eq1: RHS= -5.000000, LHS= -4.521739, error=
Eq2: RHS= -5.000000, LHS= -5.478261, error=
Eq3: RHS= 1.500000, LHS= 1.021739, error=
Eq4: RHS= 0.000000, LHS= -0.478261, error=
Eq5: RHS= -0.500000, LHS= -0.021739, error=
Eq6: RHS= 0.000000, LHS= 0.478261, error=

0.478261
0.478261
0.478261
0.478261
0.478261
0.478261

1
,
If we manually investigate the results, we can verify that all the variables are multiples of 690
they are not trivial values.
What can be interesting is that the error is the same for all six equations. Maybe it is a general
rule if the number of equations is one more than the number of variables? This leads to another
mathematical problem.

4.9

Equation systems – Summary

We have learnt through the basic skills in GNU MathProg with which we can implement linear
mathematical models: using parameters, separating the model and the data section, and most
importantly, indexing expressions. We also solved a simple but nontrivial optimization problem
about minimizing the errors in equations.
Note that the coding effort was minimal in GNU MathProg, or mathematical programming in
general, compared to solution algorithms we had to otherwise implement ourselves.
From now on, it is recommended for each subsequent optimization problem to implement a single
general model file containing the model section, but no problem data. Each problem instance the
model needs to be solved for, can be implemented in a single separate data file containing the whole
data section. Therefore, there should be as many data files as problem instances.

42
